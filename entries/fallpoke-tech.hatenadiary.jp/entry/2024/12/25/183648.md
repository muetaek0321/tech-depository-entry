---
Title: 話題のRAdamScheduleFreeをざっくり試す
Category:
- Python
- Pytorch
- 機械学習
- 画像処理
Date: 2024-12-25T18:36:48+09:00
URL: https://fallpoke-tech.hatenadiary.jp/entry/2024/12/25/183648
EditURL: https://blog.hatena.ne.jp/fallpoke/fallpoke-tech.hatenadiary.jp/atom/entry/6802418398314308376
---

お疲れ様です。

今回は機械学習の界隈で話題の**RAdamScheduleFree**という新しいoptimizerを試したいと思います。
なんでもAdamWと同等かそれ以上の性能だとか…！  
詳しい内容は作成者さんのZennをご確認ください。今回私がやるのはとりあえずの実装のみ…。

[https://zenn.dev/dena/articles/6f04641801b387:embed:cite]


[:contents]


## 条件設定（実行環境、使用モデルなど）
実行環境は以下になります。
> CPU: 13th Gen Intel(R) Core(TM) i7-13700F   2.10 GHz  
> メモリ: 32 GB  
> GPU: NVIDIA GeForce RTX 4060 Ti  
> VRAM: 16GB  
> OS: Windows11 Pro  

使用するモデルは物体検出モデルのDETRです。これまで私が実装してきたものです。  
また、データセットはVOC2012の物体検出用データセットを使用しました。  

[https://fallpoke-tech.hatenadiary.jp/entry/2024/10/31/205355:embed:cite]

ソースコードはこちらにあります。実装も反映済みです。

[https://github.com/muetaek0321/HF-ObjectDetection-Models:embed:cite]

学習設定は以下になります。比較のモデルでも同じ設定を使用しています。
```
[parameters]
num_epoches = 100
batch_size = 32
classes = [
    "person", "bird", "cat", "cow", "dog", "horse", "sheep", 
    "aeroplane", "bicycle", "boat", "bus", "car", "motorbike", 
    "train", "bottle", "chair", "diningtable", 
    "pottedplant", "sofa", "tvmonitor"
]

# 入力画像サイズ: (height, width)
input_size = [512, 512]

# データセットの形式（"coco" or "pascal_voc"）
dataset_type = "pascal_voc"

[optimizer]
lr = 1e-4
lr_backbone = 1e-5
weight_decay = 1e-4
```

### 実装
今回使用するRAdamScheduleFreeはすでにMetaのScheduleFreeのGitHubリポジトリにマージ済みです。実装自体もすごく簡単でしたね…！  
MNISTの画像分類に適用したサンプルコードがあるので、こちらを参考に実装しました。  

[https://github.com/facebookresearch/schedule_free/blob/main/examples/mnist/main.py:embed:cite]


### 結果
- 学習曲線
[f:id:fallpoke:20241225182355p:plain]
- 推論画像の一部
[f:id:fallpoke:20241225182916p:plain]
[f:id:fallpoke:20241225183100p:plain]
[f:id:fallpoke:20241225183327p:plain]

### 比較（AdamWでの結果）
- 学習曲線
[f:id:fallpoke:20241225182425p:plain]
- 推論画像の一部
[f:id:fallpoke:20241225183021p:plain]
[f:id:fallpoke:20241225183127p:plain]
[f:id:fallpoke:20241225183305p:plain]

### 所感
AdamWと比べてめちゃくちゃ安定していたことにまず驚きました。（AdamW側の学習率の設定が適正でなかった可能性もありますが…。）学習が安定した分最終的な精度もAdamWと比べてよかったように思います。ここはちゃんと評価指標で算出した方がよいのですが、実装がまだなので…。  
実装は本当に簡単だったので今ある訓練用のソースのoptimizerを変えるだけですぐ試せてしまいますね…！  
社内でも結構話題になっており、検証の段階ですが使ってみたいという声も結構出ている印象です。
これまで主流だったAdamにとって代わるのか今から楽しみです。  
