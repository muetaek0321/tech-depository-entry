---
Title: 「pfnet/plamo-embedding-1b」をChromaDBのEmbeddingで使ってみた
Category:
- Python
- Webアプリ
- 自然言語処理
Date: 2025-04-17T22:05:06+09:00
URL: https://fallpoke-tech.hatenadiary.jp/entry/2025/04/17/220506
EditURL: https://blog.hatena.ne.jp/fallpoke/fallpoke-tech.hatenadiary.jp/atom/entry/6802418398349264387
---

お疲れ様です。

今日の昼頃Preferred Networks（PFN）からPLaMoをベースにしたテキスト埋め込みモデル（Embeddingモデル）が公開されていました！  

[https://tech.preferred.jp/ja/blog/plamo-embedding-1b/:embed:cite]

この公開された「plamo-embedding-1b」ですが、他の日本語テキスト埋め込みモデルと比較してもかなり性能が良いとのこと。  
このモデル自体はHugging Faceで公開されており、ライセンスもApache v2.0ライセンスなので商用利用可。めちゃくちゃありがたいです。

[https://huggingface.co/pfnet/plamo-embedding-1b:embed:cite]


とにかくまずは使ってみたいということで、ChromaDBのEmbeddingモデルとして使ってみました。  
作成したデータベースを使ってRAGを動かすところまでやってみます。
ソースコードについてはStreamlitで作成しているチャットボットアプリの一部になります。

[https://github.com/muetaek0321/streamlit-chatbot:embed:cite]

基本的にはこれまでのEmbeddingモデル設定をplamo-embedding-1bに置き換えるだけです。  
これまでは[intfloat/multilingual-e5-base](https://huggingface.co/intfloat/multilingual-e5-base)を使用していましたがここを置き換えました。さすがにモデルサイズは大きくなっておりCPUだけの処理では時間がかかりすぎたのでCUDAを使用しています。  
データベース作成の部分とRAG実行時の入力文のベクトル化の部分をこちらに置き換えています。
```python
# ベクトル化する準備
model_kwargs = {"device": "cuda", "trust_remote_code": True}
embedding = HuggingFaceEmbeddings(
    model_name="pfnet/plamo-embedding-1b",
    model_kwargs=model_kwargs
)
```

アプリ側でRAGを実行してみました。データベースは急造で大した大きさではないですので参考程度に。  
データベースにしたのはエレファントカシマシに関するWikipediaのテキスト情報です。
おそらく以下のWikipediaの内容が取得されていますが、うまく指定した曲の内容だけを取れているように思いますね。
ちょっとまだサンプルが少ないのでもっと試していきたいところです！  
[https://ja.wikipedia.org/wiki/%E6%82%B2%E3%81%97%E3%81%BF%E3%81%AE%E6%9E%9C%E3%81%A6:title]

[f:id:fallpoke:20250417215811p:plain]
